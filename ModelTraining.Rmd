---
title: "Model Training"
author: "Lucy Whitmore"
date: "2/12/2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

packages <-  c("tidyverse",
               "ggpubr", "tidymodels", "xgboost", "caret")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
lapply(packages, library, character.only = TRUE)
```

### SETUP ###

# Load data
```{r}
slopes <- rio::import("/Volumes/devbrainlab/Lucy/BrainAGE/ChangeScoresCapstone/slopes_df.Rda")# %>% 
 # select(-c("src_subject_id", "rel_family_id"))

slopes_train <- rio::import("/Volumes/devbrainlab/Lucy/BrainAGE/ChangeScoresCapstone/slopes_train.Rda") #%>% 
#  select(-c("src_subject_id", "rel_family_id"))

slopes_test <- rio::import("/Volumes/devbrainlab/Lucy/BrainAGE/ChangeScoresCapstone/slopes_test.Rda")# %>% 
 # select(-c("src_subject_id", "rel_family_id"))
```

# Train/test split done in preprocessing

## Blueprint 
```{r}


blueprint_slopes <- recipe(x     =  slopes,
                    vars  = colnames(slopes),
                    roles = c('ID','outcome','family split variable', rep('predictor',184))) %>%  # change this
             step_zv(all_numeric()) %>%
             step_nzv(all_numeric()) %>%
             step_normalize(all_numeric_predictors())

```

## Cross-Validation
```{r}
set.seed(10152021)  # for reproducibility
# Randomly shuffle the data
    slopes_train = slopes_train[sample(nrow(slopes_train)),]

# Create 10 folds with equal size
    folds_slopes = cut(seq(1,nrow(slopes_train %>% group_by(rel_family_id))),breaks=10,labels=FALSE)
  
# Create the list for each fold 
    my.indices_slopes <- vector('list',10)
    for(i in 1:10){
        my.indices_slopes[[i]] <- which(folds_slopes!=i)
    }
      
cv_slopes <- trainControl(method = "cv",
                   index  = my.indices_slopes)
```

## Cross-Validation, grouped by Family ID
```{r}

set.seed(42)

cv_slopes <- slopes_train %>%
  group_vfold_cv(
    v = 10, 
   # repeats = 10, 
    balance = "observations",
   # strata = "interview_age",
    group = rel_family_id
  )

```


### Model Training - Elastic Net ###

```{r}
# Create the tuning grid

grid <- expand.grid(alpha = seq(0,1,.01), lambda = seq(0.001,0.5,.005)) 
  
grid
```

```{r}
# Train model
elastic_slopes <- caret::train(blueprint_slopes, 
                        data      = slopes_train, 
                        method    = "glmnet", 
                        trControl = cv_slopes,
                        tuneGrid  = grid)
```


```{r}
# Check hyperparameters & feature importance
coefs <- coef(elastic_slopes$finalModel,elastic_slopes$bestTune$lambda)
coefs

require(vip)

vip(elastic_slopes, 
    num_features = 10, 
    geom = "point") + 
theme_bw()
```

```{r}
# Predict on new data & evaluate performance
predict_te_elastic_slopes <- predict(elastic_slopes, slopes_test)
predict_te_elastic_slopes

slopes_pred_elastic <- cbind(slopes_test$interview_age,predict_te_elastic_slopes)

# Performance
rsq_te_slopes <- cor(slopes_test$interview_age,predict_te_elastic_slopes)^2
rsq_te_slopes

mae_te_slopes <- mean(abs(slopes_test$interview_age - predict_te_elastic_slopes))
mae_te_slopes

rmse_te_slopes <- sqrt(mean((slopes_test$interview_age - predict_te_elastic_slopes)^2))
rmse_te_slopes
```

```{r}
# save elastic net model
save(elastic_slopes, file = "elastic_slopes.Rdata")

save(slopes_pred_elastic, file = "slopes_pred_elastic.Rda")

```
